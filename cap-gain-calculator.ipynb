{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c692df",
   "metadata": {},
   "source": [
    "# Capital Gain Calculator (FIFO Method)\n",
    "Adapted from VBA to Python\n",
    "\n",
    "### Structures\n",
    "1. Transaction queue\n",
    "    - HashMap (key is Asset, dict is tuple of two deques)\n",
    "2. Transactions\n",
    "    - 6 properties: Timestamp, Asset (eg. BTC), Type (buy or sell), Units, Total Amount ($), IRS ID (eg. Gemi 1)\n",
    "\n",
    "### Outline\n",
    "1. Validate transaction log CSV\n",
    "    - Sort CSV by Timestamp property\n",
    "    - Ensure valid Type property and corresponding Units property sign\n",
    "    - Ensure other properties properties\n",
    "2. Input data from transaction log CSV file into a buy transaction queue and sell transaction queue for each asset (eg. transaction log with BTC and ETH transactions -> BTC-Buy, BTC-Sell, ETH-Buy, Eth-Sell)\n",
    "3. For each asset, run FIFO algorithm\n",
    "    - While there are still transactions in the sell transaction queue, match front of sell queue with front of buy queue transaction (verifying buy transaction Timestamp property is before sell transaction)\n",
    "    - When a match is found, add write buy-sell transaction to output CSV file\n",
    "    - Update remaining balance (Units and Total Amount property) on buy/sell transaction and/or remove empty transaction(s) from respective queue\n",
    "    - Run until the sell transaction queue is empty, the remaining buy transaction(s) are the carryover\n",
    "4. Create summary report\n",
    "\n",
    "\n",
    "Question:\n",
    "\n",
    "FIFO method only matters in the case that there is carryover. If there is no carryover, that means every buy has a sell?? Could we just say in the case of carryover, look back at where the most recent buy transactions were and conclude that those are the carryover inventory still in possession. \n",
    "\n",
    "Actually I'm not entirely sure, it may be that the timing of certain buy/sell affects capital gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6da7e",
   "metadata": {},
   "source": [
    "# 1. Read and Validate Transaction Log CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "91c1c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "# Define a function converting a timestamp string (must be mm/dd/yyyy hh:mm:ss) into a datetime object\n",
    "def timestamp(string):\n",
    "    return datetime.datetime.strptime(string, \"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "# Open input CSV file\n",
    "file_name = \"large_example.csv\"\n",
    "file = open(file_name, 'r')\n",
    "transaction_log = csv.DictReader(file)\n",
    "\n",
    "# Sort transaction log by Timestamp property\n",
    "transaction_log = sorted(transaction_log, key=lambda d: timestamp(d['Timestamp']))\n",
    "\n",
    "# Change datatypes of Units and Total Amount to float\n",
    "for tx in transaction_log:\n",
    "    tx['Units'] = float(tx['Units'])\n",
    "    tx['Total Amount'] = float(tx['Total Amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a069e83",
   "metadata": {},
   "source": [
    "# 2. Input Data into Transaction Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "2a81393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Create Transaction Queues\n",
    "asset_map = {}\n",
    "\n",
    "# Define buy and sell constants\n",
    "BUY = 0\n",
    "SELL = 1\n",
    "\n",
    "for tx in transaction_log:\n",
    "    # Create buy and sell deques for each asset\n",
    "    asset = tx['Asset']\n",
    "    if asset not in asset_map:\n",
    "        buy_deque = deque()\n",
    "        sell_deque = deque()\n",
    "        asset_map[asset] = (buy_deque, sell_deque)\n",
    "    \n",
    "    # Add transaction to respective deque\n",
    "    if tx['Type'] == \"Buy\":\n",
    "        asset_map[asset][BUY].appendleft(tx)\n",
    "    else:\n",
    "        asset_map[asset][SELL].appendleft(tx)\n",
    "        \n",
    "# Close input CSV File\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa02ce",
   "metadata": {},
   "source": [
    "# 3. Run FIFO Transaction Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "5cf1b6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemi 21 : -6.661338147750939e-16\n",
      "Gemi 1285 : -4.0000037504484e-08\n",
      "Gemi 654 : -1.27675647831893e-15\n",
      "Gemi 976 : 6.786238238021269e-14\n",
      "Capital Gain: 14412.059626055552\n",
      "Buy Volume: 94516198.40155134\n",
      "Sell Volume: 232793906.23770317\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open output CSV file\n",
    "file_name = \"fifo.csv\"\n",
    "file = open(file_name, 'w', encoding='UTF8', newline='')\n",
    "writer = csv.writer(file)\n",
    "\n",
    "# Define fieldnames\n",
    "fieldnames = ['Asset', 'Date Purchased', 'Date Sold', 'Units', 'Sale Price', 'Basis', 'Gain / Loss', 'IRS ID Buy', 'IRS ID Sell']\n",
    "writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "# Write fieldnames into output CSV file\n",
    "writer.writeheader()\n",
    "\n",
    "# Create dictionary to store short and long term capital gain/loss statistics\n",
    "year_summary = {}\n",
    "\n",
    "# Volume statistics\n",
    "capital_gain, buy_volume, sell_volume = 0, 0, 0\n",
    "\n",
    "# Loop through each asset\n",
    "for asset in asset_map:\n",
    "   \n",
    "    # Create dictionary to store match transaction information\n",
    "    match = {}\n",
    "    match['Asset'] = asset\n",
    "    \n",
    "    # Loop until there are no more transactions in sell deque\n",
    "    while asset_map[asset][SELL]:\n",
    "        \n",
    "        # Get earliest non-matched sell transaction\n",
    "        sell_tx = asset_map[asset][SELL].pop()\n",
    "        \n",
    "        # rounding down to 0????\n",
    "        if abs(sell_tx['Units']) < .0000001:\n",
    "            print(sell_tx['IRS ID'], \":\", sell_tx['Units'])\n",
    "            continue\n",
    "        \n",
    "        # Catch error here: While sell deque is not empty, buy deque must not be empty\n",
    "        assert(asset_map[asset][BUY])\n",
    "        \n",
    "        # Get earliest non-matched buy transaction\n",
    "        buy_tx = asset_map[asset][BUY].pop()\n",
    "        \n",
    "        # Catch error here: Buy_tx['Timestamp'] must be before sell_tx['Timestamp']\n",
    "        assert(timestamp(buy_tx['Timestamp']) <= timestamp(sell_tx['Timestamp']))\n",
    "        \n",
    "        # Populate match dictionary\n",
    "        match['IRS ID Buy'] = buy_tx['IRS ID']\n",
    "        match['IRS ID Sell'] = sell_tx['IRS ID']\n",
    "        match['Date Purchased'] = buy_tx['Timestamp']\n",
    "        match['Date Sold'] = sell_tx['Timestamp']\n",
    "        \n",
    "        # Sell transaction units are greater, so empty buy transaction\n",
    "        if abs(sell_tx['Units']) > buy_tx['Units']:\n",
    "            \n",
    "            # Calculate pro rata sale price\n",
    "            pro_rata_sale_price = buy_tx['Units'] / abs(sell_tx['Units']) * sell_tx['Total Amount']\n",
    "            \n",
    "            # Populate match dictionary\n",
    "            match['Units'] = buy_tx['Units']\n",
    "            match['Sale Price'] = pro_rata_sale_price\n",
    "            match['Basis'] = buy_tx['Total Amount']\n",
    "            \n",
    "            # Update sell transaction information and put back into deque\n",
    "            sell_tx['Units'] = sell_tx['Units'] + buy_tx['Units']\n",
    "            sell_tx['Total Amount'] = sell_tx['Total Amount'] - pro_rata_sale_price\n",
    "            asset_map[asset][SELL].append(sell_tx)\n",
    "        \n",
    "        # Buy transaction units are greater, so empty sell transaction\n",
    "        elif abs(sell_tx['Units']) < buy_tx['Units']:\n",
    "            \n",
    "            # Calculate pro rata basis\n",
    "            pro_rata_basis = abs(sell_tx['Units']) / buy_tx['Units'] * buy_tx['Total Amount']\n",
    "            \n",
    "            # Populate match dictionary\n",
    "            match['Units'] = abs(sell_tx['Units'])\n",
    "            match['Sale Price'] = sell_tx['Total Amount']\n",
    "            match['Basis'] = pro_rata_basis\n",
    "            \n",
    "            # Update buy transaction information and put back into deque\n",
    "            buy_tx['Units'] = buy_tx['Units'] + sell_tx['Units']\n",
    "            buy_tx['Total Amount'] = buy_tx['Total Amount'] - pro_rata_basis\n",
    "            asset_map[asset][BUY].append(buy_tx)\n",
    "        \n",
    "        # Transaction units are the same\n",
    "        else:\n",
    "            # Populate match dictionary\n",
    "            match['Units'] = buy_tx['Units']\n",
    "            match['Sale Price'] = sell_tx['Total Amount']\n",
    "            match['Basis'] = buy_tx['Total Amount']\n",
    "            \n",
    "        # Calculate match gain or loss\n",
    "        match['Gain / Loss'] = match['Sale Price'] - match['Basis']\n",
    "\n",
    "        # Write transaction match into output CSV file\n",
    "        writer.writerow(match)\n",
    "        \n",
    "        # Update year by year summary statistics\n",
    "        year = timestamp(sell_tx['Timestamp']).year\n",
    "        \n",
    "        if year not in year_summary:\n",
    "            year_summary[year] = {'STCG': 0, 'STCL': 0, 'LTCG': 0, 'LTCL': 0, 'Net CG': 0}\n",
    "        \n",
    "        if timestamp(sell_tx['Timestamp']) - timestamp(buy_tx['Timestamp']) < datetime.timedelta(days=365):\n",
    "            if match['Gain / Loss'] > 0:\n",
    "                year_summary[year]['STCG'] += match['Gain / Loss']\n",
    "            else:\n",
    "                year_summary[year]['STCL'] += match['Gain / Loss']\n",
    "        else:\n",
    "            if match['Gain / Loss'] > 0:\n",
    "                year_summary[year]['LTCG'] += match['Gain / Loss']\n",
    "            else:\n",
    "                year_summary[year]['LTCL'] += match['Gain / Loss']\n",
    "                \n",
    "        year_summary[year]['Net CG'] += match['Gain / Loss']\n",
    "        \n",
    "        # Update volume and total capital gain statistics\n",
    "        capital_gain += match['Gain / Loss']\n",
    "        sell_volume += sell_tx['Total Amount']\n",
    "        buy_volume += buy_tx['Total Amount']\n",
    "\n",
    "        \n",
    "    # The asset carryover are the remaining transactions in the buy deque\n",
    "    while asset_map[asset][BUY]:\n",
    "        buy_tx = asset_map[asset][BUY].pop()\n",
    "        \n",
    "        # rounding down to 0????\n",
    "        if abs(buy_tx['Units']) < .0000001:\n",
    "            print(buy_tx['IRS ID'], \":\", buy_tx['Units'])\n",
    "            continue\n",
    "        \n",
    "        # Populate match as a carryover\n",
    "        match['IRS ID Buy'] = buy_tx['IRS ID']\n",
    "        match['IRS ID Sell'] = '-'\n",
    "        match['Date Purchased'] = buy_tx['Timestamp']\n",
    "        match['Date Sold'] = '-'\n",
    "        match['Units'] = buy_tx['Units']\n",
    "        match['Sale Price'] = '-'\n",
    "        match['Basis'] = buy_tx['Total Amount']\n",
    "        match['Gain / Loss'] = '-'\n",
    "        \n",
    "        # Write carryover into output CSV file\n",
    "        writer.writerow(match)\n",
    "        \n",
    "        buy_volume += buy_tx['Total Amount']\n",
    "        \n",
    "    \n",
    "print(\"Capital Gain:\", capital_gain)\n",
    "print(\"Buy Volume:\", buy_volume)\n",
    "print(\"Sell Volume:\", sell_volume)\n",
    "print(\"\\n\")\n",
    "    \n",
    "# Close output CSV File\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbeac13",
   "metadata": {},
   "source": [
    "# 4. Create Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "aeb641e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 {'STCG': 0, 'STCL': -2860.080000000019, 'LTCG': 0, 'LTCL': 0, 'Net CG': -2860.080000000019}\n",
      "2018 {'STCG': 246135.70168479823, 'STCL': -228863.56205874242, 'LTCG': 0, 'LTCL': 0, 'Net CG': 17272.13962605556}\n"
     ]
    }
   ],
   "source": [
    "for year in year_summary:\n",
    "    print(year, year_summary[year])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
